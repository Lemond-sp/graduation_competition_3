{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 顔文字や絵文字、URLを除去する\n",
        "\n",
        "### 参考資料\n",
        "https://qiita.com/dcm_murakami/items/4c016936a739bfb2a517\n",
        "\n",
        "https://upura.hatenablog.com/entry/2018/09/18/203540"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jFR5EVNWbd_",
        "outputId": "9259e0d2-d528-46f7-f7b7-0860ce122073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nagisa\n",
            "  Downloading nagisa-0.2.8-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.6 MB 1.6 MB/s \n",
            "\u001b[?25hCollecting emoji\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 67.3 MB/s \n",
            "\u001b[?25hCollecting DyNet38\n",
            "  Downloading dyNET38-2.1-cp38-cp38-manylinux1_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 40.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from nagisa) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from nagisa) (1.15.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from DyNet38->nagisa) (0.29.32)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=bfc4a067e70b0edf43d22f26b469dfcd9f541eae2cda18bb53d471ad75f2203b\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/62/9e/a6b27a681abcde69970dbc0326ff51955f3beac72f15696984\n",
            "Successfully built emoji\n",
            "Installing collected packages: DyNet38, nagisa, emoji\n",
            "Successfully installed DyNet38-2.1 emoji-2.2.0 nagisa-0.2.8\n"
          ]
        }
      ],
      "source": [
        "!pip install nagisa emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPWQ1XQuXcWK",
        "outputId": "57301cdf-c671-416c-aac8-9a4d500a0546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/grad_comp/data\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/grad_comp/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdaqLT3vWU5A",
        "outputId": "048944fd-d740-4aec-d697-06f1aa984f4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\\\\(^o^)/']\n",
            "['m(-_-)m']\n"
          ]
        }
      ],
      "source": [
        "import nagisa\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "KAOMOJI_LEN = 5\n",
        "\n",
        "def extract_kaomoji(text):\n",
        "    \"\"\" 与えられたテキストから抽出した顔文字リストを返却する。\n",
        "        → ＼(^o^)／, m(_ _)m などの 手を含む顔文字があれば、それも抽出する\n",
        "    \"\"\"\n",
        "    results = nagisa.extract(text, extract_postags=['補助記号'])\n",
        "    words = results.words\n",
        "    kaomoji_words = []\n",
        "    kaomoji_idx = [i for i, w in enumerate(words) if len(w) >= KAOMOJI_LEN]\n",
        "    kaomoji_hands = ['ノ', 'ヽ', '∑', 'm', 'O', 'o', '┐', '/', '\\\\', '┌'] \n",
        "    # 顔文字と手を検索\n",
        "    for i in kaomoji_idx:\n",
        "        kaomoji = words[i] # 顔文字列\n",
        "        try:\n",
        "            # 顔文字の左手\n",
        "            if words[i-1] in kaomoji_hands and 0 < i:\n",
        "                kaomoji = words[i-1] + kaomoji\n",
        "            # 顔文字の右手\n",
        "            if words[i+1] in kaomoji_hands:\n",
        "                 kaomoji = kaomoji + words[i+1]\n",
        "        except IndexError:\n",
        "            pass\n",
        "        finally:\n",
        "            kaomoji_words.append(kaomoji)\n",
        "    return kaomoji_words\n",
        "\n",
        "# 顔文字除去したテキストを返す関数\n",
        "def remove_kaomoji(text):\n",
        "  res = nagisa.extract(text, extract_postags=['補助記号'])\n",
        "  kaomoji = res.words # 顔文字リスト\n",
        "  kaomoji = [t for t in kaomoji if t not in ['、','。','...','?', '?', '!', '!']] # 対象外\n",
        "  words = nagisa.tagging(text)\n",
        "  tokens = words.words\n",
        "  remove_list = [t for t in tokens if t not in kaomoji]\n",
        "  remove_text = ''.join(remove_list)\n",
        "  return remove_text\n",
        "\n",
        "text = \"今日は渋谷スクランブルスクエアに行ってきた＼(^o^)／ 夜景🏙サイコー❗️ https://hogehogehogehoge.jpg\"\n",
        "text = unicodedata.normalize('NFKC', text) # NFKC正規化\n",
        "print(extract_kaomoji(text))\n",
        "# => ['\\\\(^o^)/']\n",
        "\n",
        "text = \"ごめんなさいm(-_-)m\"\n",
        "text = unicodedata.normalize('NFKC', text) # NFKC正規化\n",
        "print(extract_kaomoji(text))\n",
        "# => ['m(-_-)m']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "l964szM6ij9T"
      },
      "outputs": [],
      "source": [
        "# ファイル処理\n",
        "filename = ['train','dev','test']\n",
        "\n",
        "for name in filename:\n",
        "  with open('text.' + name + '.txt') as fr,open('../preprocess/text.prep_' + name + '.txt',mode='w') as fw:\n",
        "    for line in fr:\n",
        "      line = re.sub(r'\\s+', '', line) # 空白削除\n",
        "      line = unicodedata.normalize('NFKC', line) # NFKC正規化\n",
        "      re_line = remove_kaomoji(line) # 顔文字抽出\n",
        "      fw.write(re_line + '\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "TX0oJWi2iumk"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('py37')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8 (default, Apr 13 2021, 12:59:45) \n[Clang 10.0.0 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "0bbcfcc1b2607f9590d16c6d822fed489540cbd3ba0db4dddb602648fbc29ae6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
